- time: 9:45-10:00
  info: "<b>Day 3 Overview</b> <i>Seminar Room 23.21.00.046</i>, <i>Seminar Room 23.21.00.48</i><br> Information for the day"
- time: 10:00-11:00
  info: "<b>Workshop</b> <i>Seminar Room 23.21.00.46</i><br><details><summary>▼ From Zero to Terminal Hero - <i>Akhilesh Kakolu Ramarao</i></summary>\nClick <a href='/css/2023_style/TalkSlides/RAMARAO.pdf'>here</a> to download the slides.\n<br>This workshop will provide an introduction to the Linux terminal and Vim editor. You will learn how to navigate and manipulate files and directories using terminal interface, as well as execute basic system operations such as managing processes and installing softwares.\n\nThe second half of the workshop will focus on the introduction to the Vim editor, a powerful and customizable text editor widely used by programmers. You will learn how to navigate, edit, and save files in Vim, and other commonly-used commands.\n\nBy the end of the workshop, you will have gained a solid foundation in using both Terminal and Vim, and be able to use it confidently in your daily work.\n\n---Pre-requisites---\nFor Windows Users:\nYou need to have WSL2 installed on your laptop before the session. You can do so by following this guide: <a href='https://docs.slam.phil.hhu.de/#/wsl'>https://docs.slam.phil.hhu.de/#/wsl</a>\n\nFor MacOS Users:\nNo prerequisites required.\n\nFor Linux Users:\nNo prerequisites required.</details>"
- time: 10:00-10:30
  info: "<b>Talk</b> <i>Seminar Room 23.21.00.48</i> <br><details><summary>▼ SEMSAI: Self-Referential Multi-Scale Modelling and Simulation of Severe Infectious Diseases <i>Annegret Janzso</i></summary>\nClick <a href='/css/2023_style/TalkSlides/JANZSO.pptx'>here</a> to download the slides.\n<br>As seen for example during the Covid-19 pandemic, predictions on number of infections tend to be overshot by models, causing a decrease in acceptance in simulation-based predictions. This also causes the population to have less trust in the information itself, as well as those who convey it. To tackle this, the SEMSAI project aims to improve predictions to better mirror reality, by also portraying a change in population behavior based on given predictions. This reflexive modeling process is used to regain trust in conveyed information and give better information on what the best call for action is in a given situation. The influence of (scientific) communication on human behavior, as well as generally introducing agent-based cognitive social simulations as a tool that has interesting applications within linguistics and computational linguistics, which is not yet used much in those fields.</details>"
- time: 11:10-11:30
  info: "<b>Coffee Break</b> <i>Seminar Room 23.21.00.44</i>"
- time: 11:30-12:40
  info: "<b>Workshop</b> <i>Seminar Room 23.21.00.046</i><br><details><summary>▼ One word, a thousand pictures. Text to image Generation with Stable Diffusion - <i>Adrienne Wright</i></summary>\n<a href='https://colab.research.google.com/drive/1wrPjVzu9cvrzzBvR2F7IBHBdCVDl_Kh5?usp=sharing'>Google Colab Notebook</a>\n\n<a href='https://docs.google.com/presentation/d/1dBVPVxsNRw82Dcy2vU_cz8NOf6Wc3P5Flz9St-u3MEU/edit?usp=sharing'>Slides</a>\n<br>Diffusion models are capable of generating images from text prompts. How do these models encode linguistic information and represent it pictorially? The first half of this workshop will present the basic architecture behind these models, followed by a hands-on latter half, where participants will be able to use a GPU in a custom Colab notebook to transform text into images with Stable Diffusion. We will dive into the computational and linguistic theory behind prompt engineering and parameter adjustment and try it out for ourselves.\n\nThis workshop draws on my work in the LMU master seminars 'Computational Creativity' at the Centre for Information and Speech Processing, in which I designed a twitter bot that responded to tweets of dreams with pictorial dream sequences (<a href'https://github.com/gitovska/hallie-sue-nation'>https://github.com/gitovska/hallie-sue-nation</a>) and 'Creating Art(efacts): Computer-based Image Generation and Editing' to be taken this semester at the Computer Vision and Learning Group, where Stable Diffusion was developed.</details><hr><b>Workshop</b><i>Seminar Room 23.21.00.048</i><br><details><summary>▼Hey Mycroft, let's play a game! - Developing skills for an open source voice assistant - <i>Mikhail Sonkin, Katja Konermann</i></summary>[SLIDES]<br>Voice assistants are all around us. For some of them, such as Alexa by Amazon, it is possible to develop your own applications. However, voice assistants made by large companies often remain a black box, as most of their code base is proprietary. Additionally, privacy concerns might make some people reluctant to use these assistants or develop skills for them.\n\nIn this workshop, we will take a look at an alternative – the open source voice assistant Mycroft by Mycroft AI. What are its upsides compared to its market-dominating competitors? Where does it fall short?\n\nPrimarily, we will focus on guiding you through the development of a Mycroft Skill, explaining key components crucial for the design of a successful user interaction: Launching a skill with an intent, Responding to an utterance, asking follow-up questions, extracting relevant information from the user's utterance, finding information on the Internet, storing data, handling errors and designing fall-back answers, by the end, we will have our own module fully integrated into Mycroft's skill set. Join us to play around with Mycroft!</details>" 
- time: 12:40 - 13:30
  info: "<b>Lunch</b><i> Seminar Room 23.21.00.044</i>"
- time: 14:30-15:00
  info: "<b>Snacks</b><i> Haus der Universität</i>" 
- time: 15:00-16:00
  info: "<b>Keynote talk by Univ. Prof. Dr. Kevin Tang</b> <i>Haus der Universität</i><br><details><summary>▼The use of computational models to determine acoustic and syntactic variations in Parkinson's Disease patients.</summary>Speech can be used as a non-invasive biomarker to capture fine changes in speech patterns in normal populations and individuals diagnosed with neuromotor disorders, such as Parkinson's Disease (PD).\nIn this talk, I will demonstrate how computational models that are linguistically-informed can quantify acoustic and syntactic variations in PD patients.\n\n<b>Paper ressources:</b>\n1) <a href='http://dx.doi.org/10.1121/10.0017247'>From sonority hierarchy to posterior probability as a measure of lenition: The case of Spanish stops</a>\n2) <a href='http://dx.doi.org/10.3390/languages8020098'>Quantitative Acoustic versus Deep Learning Metrics of Lenition</a>\n3) <a href='https://pubs.aip.org/asa/poma/article/50/1/060002/2879418/Lenition-measures-Neural-networks-posterior'>Lenition measures: Neural networks’ posterior probability vs. acoustic cues</a>\n4) <a href='https://doi.org/10.31234/osf.io/4wtc8'>Measuring Gradient Effects of Alcohol on Speech with Neural Networks’ Posterior Probability of Phonological Features</a>\n5) <a href='https://doi.org/10.17605/OSF.IO/GCH7S'>Language production in Parkinson's Disease</a>\n\n<b>Poster:</b>\n1) <a href='https://selma.ece.ufl.edu/2023/04/uf-undergraduate-research-symposium_poster-presentation/'>UF undergraduate research symposium poster presentation</a></details>" 
- time: 16:00 - Open
  info: "<b>Closing plenary</b><i> Haus der Universität</i><br>Closing talk from the organisation team, thanks and shoutouts"

